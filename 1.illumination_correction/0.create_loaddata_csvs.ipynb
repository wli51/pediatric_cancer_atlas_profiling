{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LoadData CSVs to use for illumination correction\n",
    "\n",
    "In this notebook, we create a LoadData CSV that contains paths to each channel per image set for CellProfiler to process. \n",
    "We can use this LoadData CSV to run illumination correction (IC) pipeline that saves IC functions in `npy` file format and extract image quality metrics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "import loaddata_utils as ld_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for parameters to make loaddata csv\n",
    "index_directory = pathlib.Path(\"/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pilot_data/SN0313537/\")\n",
    "config_dir_path = pathlib.Path(\"./config_files\").absolute()\n",
    "output_csv_dir = pathlib.Path(\"./loaddata_csvs\")\n",
    "output_csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Find all 'Images' folders within the directory\n",
    "images_folders = list(index_directory.rglob('Images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LoadData CSVs for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/KP-N-YN_config.yml')]\n",
      "KP-N-YN_Re-imaged_BR00143977_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/KP-N-YN_config.yml')]\n",
      "KP-N-YN_Re-imaged_BR00143979_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/KP-N-YN_config.yml')]\n",
      "KP-N-YN_Re-imaged_BR00143981_loaddata_original.csv is created!\n",
      "BR00143979_loaddata_original.csv is created!\n",
      "BR00143978_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/CHP-212_config.yml')]\n",
      "CHP-212_Re-imaged_BR00143980_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/CHP-212_config.yml')]\n",
      "CHP-212_Re-imaged_BR00143978_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/CHP-212_config.yml')]\n",
      "CHP-212_Re-imaged_BR00143976_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/NB-1_config.yml')]\n",
      "NB-1_Re-imaged_BR00143981_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/NB-1_config.yml')]\n",
      "NB-1_Re-imaged_BR00143977_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/NB-1_config.yml')]\n",
      "NB-1_Re-imaged_BR00143979_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/SK-N-MC_config.yml')]\n",
      "SK-N-MC_Re-imaged_BR00143978_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/SK-N-MC_config.yml')]\n",
      "SK-N-MC_Re-imaged_BR00143980_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/SK-N-MC_config.yml')]\n",
      "SK-N-MC_Re-imaged_BR00143976_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/SK-N-AS_config.yml')]\n",
      "SK-N-AS_Re-imaged_BR00143981_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/SK-N-AS_config.yml')]\n",
      "SK-N-AS_Re-imaged_BR00143979_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/SK-N-AS_config.yml')]\n",
      "SK-N-AS_Re-imaged_BR00143977_loaddata_original.csv is created!\n",
      "BR00143981_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/KNS-42_config.yml')]\n",
      "KNS-42_Re-imaged_BR00143981_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/KNS-42_config.yml')]\n",
      "KNS-42_Re-imaged_BR00143979_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/KNS-42_config.yml')]\n",
      "KNS-42_Re-imaged_BR00143977_loaddata_original.csv is created!\n",
      "BR00143976_loaddata_original.csv is created!\n",
      "BR00143977_loaddata_original.csv is created!\n",
      "BR00143980_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/A-673_config.yml')]\n",
      "A-673_Re-imaged_BR00143976_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/A-673_config.yml')]\n",
      "A-673_Re-imaged_BR00143978_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/A-673_config.yml')]\n",
      "A-673_Re-imaged_BR00143980_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/SH-SY5Y_config.yml')]\n",
      "SH-SY5Y_Re-imaged_BR00143980_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/SH-SY5Y_config.yml')]\n",
      "SH-SY5Y_Re-imaged_BR00143976_loaddata_original.csv is created!\n",
      "Matching configs found: [PosixPath('/home/weishanli/Waylab/ALSF_pilot/pediatric_cancer_atlas_profiling/1.illumination_correction/config_files/SH-SY5Y_config.yml')]\n",
      "SH-SY5Y_Re-imaged_BR00143978_loaddata_original.csv is created!\n"
     ]
    }
   ],
   "source": [
    "# Loop through each folder and create a LoadData CSV\n",
    "for folder in images_folders:\n",
    "    # Get the first folder directly under the index_directory\n",
    "    relative_path = folder.relative_to(index_directory)\n",
    "    first_folder = relative_path.parts[0]  # First-level folder\n",
    "    \n",
    "    # Generate the plate name and find matching config file based on folder structure\n",
    "    if first_folder.startswith('BR00'):\n",
    "        plate_name = first_folder.split('_')[0]  # Take the first part\n",
    "        config_path = config_dir_path / \"config.yml\"  # Use default config for BR00\n",
    "\n",
    "    elif first_folder.startswith('2024'):\n",
    "        second_folder = relative_path.parts[1]  # Second-level folder\n",
    "        part1 = '_'.join(first_folder.split('_')[-2:])  # Last two parts of first folder (\"CellLine_Re-imaged\")\n",
    "        part2 = second_folder.split('_')[0]  # First part of second folder (BR00 ID)\n",
    "\n",
    "        # Combine to make plate name for saving CSV\n",
    "        plate_name = f\"{part1}_{part2}\" \n",
    "\n",
    "        # Find the matching config file by matching part1 with the config file's prefix\n",
    "        matching_configs = list(config_dir_path.glob(f\"{part1.split('_')[0]}_*.yml\"))\n",
    "        \n",
    "        # Debugging print to check if matching config files are found\n",
    "        print(f\"Matching configs found: {matching_configs}\")\n",
    "\n",
    "        if matching_configs:\n",
    "            config_path = matching_configs[0]  # Take the first match\n",
    "        else:\n",
    "            print(f\"No matching config file for: {part1}\")\n",
    "            continue  # Skip if no matching config file\n",
    "\n",
    "    else:\n",
    "        print(f\"Unexpected folder pattern: {folder}\")\n",
    "        continue  # Skip if not matching patterns\n",
    "\n",
    "    # Create LoadData output path per plate\n",
    "    path_to_output_csv = (output_csv_dir / f\"{plate_name}_loaddata_original.csv\").absolute()\n",
    "\n",
    "    # Call the function to create the LoadData CSV\n",
    "    ld_utils.create_loaddata_csv(\n",
    "        index_directory=folder,\n",
    "        config_path=config_path,  # Use the matched config file\n",
    "        path_to_output=path_to_output_csv,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat the re-imaged data back to their original plate and remove the original poor quality data paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect a list of original CSVs and identify unique plate IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 BR00 IDs: ['BR00143976', 'BR00143977', 'BR00143978', 'BR00143979', 'BR00143980', 'BR00143981']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Find all CSV files in the output directory\n",
    "csv_files = list(output_csv_dir.glob(\"*.csv\"))\n",
    "\n",
    "# Step 2: Extract unique BR00 IDs from filenames\n",
    "br00_pattern = re.compile(r\"(BR00\\d+)\")  # Regex to match 'BR00' followed by digits\n",
    "\n",
    "# Collect all matching BR00 IDs from filenames\n",
    "br00_ids = {br00_pattern.search(csv_file.stem).group(1) \n",
    "            for csv_file in csv_files \n",
    "            if br00_pattern.search(csv_file.stem)}\n",
    "\n",
    "# Sort BR00 IDs numerically to be consistent in ordering\n",
    "br00_ids = sorted(br00_ids, key=lambda x: int(x[4:]))  # Convert digits part to integer for numerical sorting\n",
    "\n",
    "print(f\"Found {len(br00_ids)} BR00 IDs: {br00_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track/store files and add a metadata column for if a row is re-imaged or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example DataFrame for BR00 ID: BR00143976\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName_OrigBrightfield</th>\n",
       "      <th>PathName_OrigBrightfield</th>\n",
       "      <th>Metadata_Reimaged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r11c03f02p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r11c03f05p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r11c03f06p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r11c03f07p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r11c03f08p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>r14c12f05p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>r14c12f06p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>r14c12f07p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>r14c12f08p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>r14c12f09p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2847 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FileName_OrigBrightfield  \\\n",
       "0     r11c03f02p01-ch1sk1fk1fl1.tiff   \n",
       "1     r11c03f05p01-ch1sk1fk1fl1.tiff   \n",
       "2     r11c03f06p01-ch1sk1fk1fl1.tiff   \n",
       "3     r11c03f07p01-ch1sk1fk1fl1.tiff   \n",
       "4     r11c03f08p01-ch1sk1fk1fl1.tiff   \n",
       "...                              ...   \n",
       "2842  r14c12f05p01-ch1sk1fk1fl1.tiff   \n",
       "2843  r14c12f06p01-ch1sk1fk1fl1.tiff   \n",
       "2844  r14c12f07p01-ch1sk1fk1fl1.tiff   \n",
       "2845  r14c12f08p01-ch1sk1fk1fl1.tiff   \n",
       "2846  r14c12f09p01-ch1sk1fk1fl1.tiff   \n",
       "\n",
       "                               PathName_OrigBrightfield  Metadata_Reimaged  \n",
       "0     /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "1     /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "2     /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "3     /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "4     /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "...                                                 ...                ...  \n",
       "2842  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "2843  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "2844  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "2845  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "2846  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...               True  \n",
       "\n",
       "[2847 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Initialize storage to track used files and find proper column order \n",
    "br00_dataframes = {br_id: [] for br_id in br00_ids}\n",
    "used_files = set()  # Store filenames used in the process\n",
    "concat_files = []  # Track new concatenated CSV files\n",
    "\n",
    "# Load one BR00 starting CSV that will have the correct column order\n",
    "column_order = pd.read_csv(pathlib.Path(f\"{output_csv_dir}/{list(br00_ids)[0]}_loaddata_original.csv\"), nrows=0).columns.tolist()\n",
    "\n",
    "# Step 4: Add 'Metadata_Reimaged' column and group by BR00 ID\n",
    "for csv_file in csv_files:\n",
    "    filename = csv_file.stem\n",
    "    match = br00_pattern.search(filename)\n",
    "\n",
    "    if match:\n",
    "        br_id = match.group(1)\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        loaddata_df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Reorder DataFrame columns to match the correct column order\n",
    "        loaddata_df = loaddata_df[column_order]  # Ensure the columns are in the correct order\n",
    "\n",
    "        # Add 'Metadata_Reimaged' column based on filename\n",
    "        loaddata_df['Metadata_Reimaged'] = 'Re-imaged' in filename\n",
    "\n",
    "        # Append the DataFrame to the corresponding BR00 group\n",
    "        br00_dataframes[br_id].append(loaddata_df)\n",
    "\n",
    "        # Track this file as used\n",
    "        used_files.add(csv_file.name)\n",
    "\n",
    "# Print an example DataFrame (first BR00 group)\n",
    "example_id = next(iter(br00_dataframes))  # Get the first BR00 ID\n",
    "example_df = pd.concat(br00_dataframes[example_id], ignore_index=True)\n",
    "print(f\"\\nExample DataFrame for BR00 ID: {example_id}\")\n",
    "example_df.iloc[:, [0, 1, -1]] # Display only the first two and last column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat the re-imaged and original data for the same plate and remove any duplicate wells that come from the original data\n",
    "\n",
    "We remove the duplicates that aren't re-imaged since they are of poor quality. We want to analyze the re-imaged data from those same wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: loaddata_csvs/BR00143976_concatenated.csv\n",
      "Saved: loaddata_csvs/BR00143977_concatenated.csv\n",
      "Saved: loaddata_csvs/BR00143978_concatenated.csv\n",
      "Saved: loaddata_csvs/BR00143979_concatenated.csv\n",
      "Saved: loaddata_csvs/BR00143980_concatenated.csv\n",
      "Saved: loaddata_csvs/BR00143981_concatenated.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Concatenate DataFrames, drop duplicates, and save per BR00 ID\n",
    "for br_id, dfs in br00_dataframes.items():\n",
    "    if dfs:  # Only process if there are matching files\n",
    "        concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        # Drop duplicates, prioritizing rows with 'Metadata_Reimaged' == True\n",
    "        deduplicated_df = concatenated_df.sort_values(\n",
    "            'Metadata_Reimaged', ascending=False\n",
    "        ).drop_duplicates(subset=['Metadata_Well', 'Metadata_Site'], keep='first')\n",
    "\n",
    "        # Sort by 'Metadata_Col', 'Metadata_Row', and 'Metadata_Site\n",
    "        sorted_df = deduplicated_df.sort_values(\n",
    "            ['Metadata_Col', 'Metadata_Row', \"Metadata_Site\"], ascending=True\n",
    "        )\n",
    "\n",
    "        # Save the cleaned, concatenated, and sorted DataFrame to a new CSV file\n",
    "        output_path = output_csv_dir / f\"{br_id}_concatenated.csv\"\n",
    "        sorted_df.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"Saved: {output_path}\")\n",
    "        concat_files.append(output_path)  # Track new concatenated files\n",
    "    else:\n",
    "        print(f\"No files found for {br_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm that all LoadData CSV files were included in previous concat (avoid data loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files were successfully used.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Verify all files were used\n",
    "unused_files = set(csv_file.name for csv_file in csv_files) - used_files\n",
    "\n",
    "if unused_files:\n",
    "    print(\"Warning: Some files were not used in the concatenation!\")\n",
    "    for file in unused_files:\n",
    "        print(f\"Unused: {file}\")\n",
    "else:\n",
    "    print(\"All files were successfully used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the original CSV files to prevent CellProfiler from using them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: loaddata_csvs/KNS-42_Re-imaged_BR00143979_loaddata_original.csv\n",
      "Removed: loaddata_csvs/SK-N-MC_Re-imaged_BR00143980_loaddata_original.csv\n",
      "Removed: loaddata_csvs/NB-1_Re-imaged_BR00143981_loaddata_original.csv\n",
      "Removed: loaddata_csvs/SH-SY5Y_Re-imaged_BR00143978_loaddata_original.csv\n",
      "Removed: loaddata_csvs/SK-N-AS_Re-imaged_BR00143979_loaddata_original.csv\n",
      "Removed: loaddata_csvs/KP-N-YN_Re-imaged_BR00143977_loaddata_original.csv\n",
      "Removed: loaddata_csvs/A-673_Re-imaged_BR00143980_loaddata_original.csv\n",
      "Removed: loaddata_csvs/KNS-42_Re-imaged_BR00143981_loaddata_original.csv\n",
      "Removed: loaddata_csvs/CHP-212_Re-imaged_BR00143976_loaddata_original.csv\n",
      "Removed: loaddata_csvs/KNS-42_Re-imaged_BR00143977_loaddata_original.csv\n",
      "Removed: loaddata_csvs/KP-N-YN_Re-imaged_BR00143981_loaddata_original.csv\n",
      "Removed: loaddata_csvs/BR00143976_loaddata_original.csv\n",
      "Removed: loaddata_csvs/SK-N-MC_Re-imaged_BR00143976_loaddata_original.csv\n",
      "Removed: loaddata_csvs/BR00143980_loaddata_original.csv\n",
      "Removed: loaddata_csvs/SK-N-AS_Re-imaged_BR00143977_loaddata_original.csv\n",
      "Removed: loaddata_csvs/BR00143978_loaddata_original.csv\n",
      "Removed: loaddata_csvs/BR00143979_loaddata_original.csv\n",
      "Removed: loaddata_csvs/NB-1_Re-imaged_BR00143979_loaddata_original.csv\n",
      "Removed: loaddata_csvs/SK-N-MC_Re-imaged_BR00143978_loaddata_original.csv\n",
      "Removed: loaddata_csvs/A-673_Re-imaged_BR00143976_loaddata_original.csv\n",
      "Removed: loaddata_csvs/SH-SY5Y_Re-imaged_BR00143980_loaddata_original.csv\n",
      "Removed: loaddata_csvs/SH-SY5Y_Re-imaged_BR00143976_loaddata_original.csv\n",
      "Removed: loaddata_csvs/BR00143977_loaddata_original.csv\n",
      "Removed: loaddata_csvs/SK-N-AS_Re-imaged_BR00143981_loaddata_original.csv\n",
      "Removed: loaddata_csvs/CHP-212_Re-imaged_BR00143978_loaddata_original.csv\n",
      "Removed: loaddata_csvs/A-673_Re-imaged_BR00143978_loaddata_original.csv\n",
      "Removed: loaddata_csvs/BR00143981_loaddata_original.csv\n",
      "Removed: loaddata_csvs/CHP-212_Re-imaged_BR00143980_loaddata_original.csv\n",
      "Removed: loaddata_csvs/KP-N-YN_Re-imaged_BR00143979_loaddata_original.csv\n",
      "Removed: loaddata_csvs/NB-1_Re-imaged_BR00143977_loaddata_original.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Remove all non-concatenated CSVs to avoid confusion\n",
    "for csv_file in csv_files:\n",
    "    if csv_file not in concat_files:  # Keep only new concatenated files\n",
    "        csv_file.unlink()  # Delete the file\n",
    "        print(f\"Removed: {csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alsf_cp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
